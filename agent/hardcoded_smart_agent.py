from typing import TypeVar, List, Optional, Dict
from agent.memory.trees import BinaryTreeNode, BinaryTree, BoundedBinaryTree
from agent.memory.observations import CompleteMemory, SimpleMemory

Goal = TypeVar("Goal")
RawGoal = TypeVar("RawGoal")
Environment = TypeVar("Environment")
State = TypeVar("State")
Action = TypeVar("Action")


class HardcodedSmartAgent:
    def __init__(self, gamma, simple_agent, planning_terminator, subgoal_maker, optimizer):
        self.gamma: float = gamma
        self.simple_agent = simple_agent 
        self.planning_terminator = planning_terminator
        self.subgoal_maker = subgoal_maker
        self.observers: Dict[str, "Submodule"] = {}
        self.planning_tree: BinaryTree[CompleteMemory] = None
        self.history: BinaryTree[SimpleMemory] = []

        

    def reset(self, env: Environment, goal: Goal):
        """
            Needs to be called before running in a new environment
            or with a new goal. Prepares the agent to pursue the goal
            in the given environment
            Parameters
            ----------
            env: Environment
                the environment that is about to be solved, can change each timestep
            goal: RawGoal
                the goal that will be pursued, in the form that is generated by 
                external sources
        """
        if self.planning_tree is not None:
            self.history.append(self.simplify_tree(self.planning_tree))
        start: CompleteMemory = CompleteMemory(self.gamma, goal=None)
        start.states.append(env.state())
        end: CompleteMemory = CompleteMemory(self.gamma, goal=goal)

        self.planning_tree = BoundedBinaryTree(start, end)

    def act(self, state: State) -> Action:
        """
            Calculates and returns the action to take at the current timestep.
            Executes planning and goal abandonment on-the-fly as needed
            Parameters
            ----------
            state: State
                observation for the current timestep (no preprocessing)
            Returns:
            --------
            action: Action
                the action to be taken at the current timestep, in a form that
                can be directly input to the environment
        """
        immediate_goal: Goal = self.get_actionable_goal(state)
        return self.simple_executor.act(immediate_goal)

    def observe(self, first_state: State, action: Action, reward: float, 
            done: bool, second_state: Optional[State]) -> None:
        """
            Observes the results of the most recent action that the agent took.
            Is used for logging in to memory, which can be used for future training
            Parameters
            ----------
            state: State
                the state that the agent was in before acting
            action: Action
                the action the agent took
            reward: Reward
                the reward that the agent received during this timestep
            done: bool
                whether or not the environment's episode has terminated
            second_state: Optional[State]
                the state that the agent ended in after taking the action
                may be None if done==True
        """
        pass

    def get_actionable_goal(self, state: State) -> Goal:
        """
            Plans for and returns the next actionable goal for the agent.
            An actionable goal is a goal that will be fed directly in to 
            simple_executor.act. Will abandon the current goal if necessary
            Parameters
            ----------
            state: State
                the current state that the agent is in at time of query
            Returns
            -------
            goal: Goal
                the next actionable goal that can be directly pursued
        """
        if self.current_actionable_goal is None:
            if self.should_abandon(state, self.current_actionable_goal.goal):
                self.abandon_subgoal(self.current_actionable_goal)
                return self.get_actionable_goal(state)
            else: return self.current_actionable_goal.goal
        else: return self.plan(state)

    def plan(self, state: State) -> Goal:
        """
            Computes all planning necessary to get the next actionable goal
            at the current state, respecting all existing goals that have already
            been planned. Sets current_actionable_goal to result
            NOTE: assumes that the current_actionable_goal (if set) has been finished
            and will plan for the next goal, overwriting it
            NOTE: currently can only plan for the immediate future to the next
            existing goal
            Parameters
            ----------
            state: State
                the current state that the agent is in at time of planning
            Returns
            -------
                the next current_actionable_goal that can be directly executed
        """
        next_goal: BinaryTreeNode[Goal] = self.get_next_goal()
        if not self.should_plan_for(state, next_goal.goal):
            self.current_actionable_goal = next_goal
            return self.current_actionable_goal.goal
        else:
            chosen_subgoal: Goal = self.get_subgoal(state, next_goal.goal)
            self.add_subgoal(chosen_subgoal, next_goal)
            return self.plan(state)

    def abandon_subgoal(self, goal_node: BinaryTreeNode[Goal]) -> None:
        """
            Abandons a subgoal and sets the next_goal to be pursued to 
            the next planned goal
            NOTE: this does not necessariliy result in an actionable goal
            being chosen 
            NOTE: currently can only abandon the next goal and cannot abandon
            our highest level goal
            Parameters
            ----------
            goal_node: BinaryTreeNode[Goal]
                the node in the planning tree containing the goal to be abandoned
                uses node instead of goal for easy traversal of planning tree
        """
        # right now, only can abandon currently active goals
        assert goal_node == self.get_next_goal()
        # can't abandon our highest level goal
        assert goal_node.goal != self.highest_goal

        if goal_node == self.current_actionable_goal:
            self.current_actionable_goal = None
        self.next_goal: BinaryTreeNode[Goal] = self.next_planned_goal_after(goal_node)

    def add_subgoal(self, subgoal: Goal, existing_goal: BinaryTreeNode[Goal]) -> None:
        """
            adds the subgoal specified as the goal that must be achieved 
            immediately prior to existing_goal in the planning tree.
            NOTE: this does not preclude other goals coming in between them later
            Parameters
            ----------
            subgoal: Goal
                the new subgoal to be added to the planning tree
            existing_goal: BinaryTreeNode[Goal]
                the existing goal in the planning treethat 'subgoal' is a subgoal of 
                uses node instead of goal for easy traversal of planning tree
        """
        self.planning_tree.add_left(subgoal, existing_goal)

    def next_planned_goal_after(self, goal_node: BinaryTreeNode[Goal]) -> BinaryTreeNode[Goal]:
        """
            gets the next goal in the planning tree that must be achieved once
            the goal at goal_node is completed.
            NOTE: this doesn't do any planning, just gets the next planned goal
            Parameters
            ----------
            goal_node: BinaryTreeNode[Goal]
                node in the planning tree, containing the goal chronologically
                right before the result in the existing plan
                uses node instead of goal for easy traversal of planning tree
            Returns
            -------
            next_goal: BinaryTreeNode[Goal]
                the next solidified node in the planning tree after 'goal_node'
        """
        return self.planning_tree.get_next_right(goal_node)

    def should_abandon(self, state: State, goal: Goal) -> bool:
        """
            decides whether or not the goal should be abandoned, given the 
            current state of the agent. 
            NOTE: a goal may be abandoned either because there is no more progress 
            that can be made on it(e.g. it is finished or impossible)
            OR because it is no longer worth completing
            Parameters
            ----------
            state: State
                the current state that the agent is in
            goal: Goal
                the current goal that the agent is pursuing
            Returns
            -------
            abandon? : bool
                whether or not to abandon the current subgoal.
        """
        return self.simple_executor()

    def should_plan_for(self, state: State, goal: Goal) -> bool:
        """
            opposite of 'is_trivial' in the previous formalization
            returns True if the agent should continue creating subgoals
            for the given goal. Should call simple_executor.act instead
            if False
            Parameters
            ----------
            state: State
                the current state that the agent is in
            goal: Goal
                the goal that the agent is considering whether or not to plan for
            Returns
            -------
            plan? : bool
                True if the agent should continue creating subplans
        """
        pass
    
    def get_subgoal(self, state: State, goal: Goal) -> Goal:
        """
            devises and chooses a subgoal for the current goal
            Parameters
            ----- -----Z
            state: State
                the current state that the agent is in
            goal: Goal
                the goal that the agent is considering whether or not to plan for
            Returns
            -------
            goal: Goal
                the next level subgoal that the agent should pursue before the 
                current goal
        """
        pass